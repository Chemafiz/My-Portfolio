{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5376d1",
   "metadata": {},
   "source": [
    "# Digits recognition with supervised and unsupervised ML algorithms\n",
    "### Using \"classical\" ML algorithms to recognise hand-written digits. \n",
    "It is obvious that even with high accuracy, the variance of such a model will be too large. The project aims to see the possibilities of algorithms without the use of deep learning and is a sandbox for various techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "205bf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_predict,  cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442f313",
   "metadata": {},
   "source": [
    "# Downloading and analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3861d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing MNIST dataset with handwritten digits \n",
    "\n",
    "# from sklearn.datasets import fetch_openml\n",
    "df = fetch_openml(\"mnist_784\", version=1)\n",
    "\n",
    "# downloading mnist data every time is ineffective, saving them once as a file then reading them is much faster\n",
    "\n",
    "with open(\"data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f368a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "# with open(\"data.pickle\", \"rb\") as f:\n",
    "#     df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b6b822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividing dataset into data and target datasets\n",
    "X, y = np.array(df[\"data\"]), np.array(df[\"target\"])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8a834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc217fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cbd1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "#y data are str type, let's transform it\n",
    "print(type(y[0]))\n",
    "y = y.astype(\"uint8\")\n",
    "print(type(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ee37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  9.861%\n",
      "1:  11.253%\n",
      "2:  9.986%\n",
      "3:  10.201%\n",
      "4:  9.749%\n",
      "5:  9.019%\n",
      "6:  9.823%\n",
      "7:  10.419%\n",
      "8:  9.750%\n",
      "9:  9.940%\n"
     ]
    }
   ],
   "source": [
    "#distribution of the number of digits in a data set\n",
    "for number in range(10):\n",
    "    print(f\"{number}: {len(y[y==number])/len(y) * 100: .3f}%\")\n",
    "#it seems that dataset is not very skewed, that's good :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0572d33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#checking if there are nan values\n",
    "print(np.isnan(X).sum())\n",
    "print(np.isnan(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216b8362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing sample image of number\n",
    "plt.imshow(X[0].reshape(28,28), cmap = \"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f95e6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting datasets into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cda029",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b20348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn model accuracy: [0.9673  0.96945 0.96735]\n",
      "sgd model accuracy: [0.8614  0.88205 0.8757 ]\n",
      "rfg model accuracy: [0.9658  0.96815 0.96545]\n"
     ]
    }
   ],
   "source": [
    "#at first it would be a good idea to find the most promising model\n",
    "knn_clf = KNeighborsClassifier()\n",
    "sgd_clf = SGDClassifier()\n",
    "rfg_clf = RandomForestClassifier()\n",
    "\n",
    "print(\"knn model accuracy:\", cross_val_score(knn_clf, X_train, y_train, cv=3, scoring=\"accuracy\"))\n",
    "print(\"sgd model accuracy:\", cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\"))\n",
    "print(\"rfg model accuracy:\", cross_val_score(rfg_clf, X_train, y_train, cv=3, scoring=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3168f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scaler': [Normalizer()], 'classifier': [KNeighborsClassifier()], 'classifier__n_neighbors': [3, 5, 7]}\n"
     ]
    }
   ],
   "source": [
    "#the knn model seems to be the most promising, let's tune the hyperparameters\n",
    "#building pipeline \n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "params= {}\n",
    "# params[\"scaler\"] = [Normalizer(), StandardScaler(), MinMaxScaler()] \n",
    "params[\"scaler\"] = [Normalizer()] \n",
    "params[\"classifier\"] = [KNeighborsClassifier()]\n",
    "params[\"classifier__n_neighbors\"] = [3, 5, 7]\n",
    "\n",
    "print(params)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipeline, params, cv=3, scoring = \"accuracy\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5062f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier': [KNeighborsClassifier(n_neighbors=3)],\n",
       "                         'classifier__n_neighbors': [3, 5, 7],\n",
       "                         'scaler': [Normalizer()]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "092a72f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_classifier__n_neighbors</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.963287</td>\n",
       "      <td>0.244737</td>\n",
       "      <td>311.222089</td>\n",
       "      <td>22.211935</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>3</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>{'classifier': KNeighborsClassifier(n_neighbor...</td>\n",
       "      <td>0.97415</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.974017</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.523836</td>\n",
       "      <td>2.353290</td>\n",
       "      <td>324.330310</td>\n",
       "      <td>4.107602</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>5</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>{'classifier': KNeighborsClassifier(n_neighbor...</td>\n",
       "      <td>0.97330</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.973200</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.222510</td>\n",
       "      <td>2.090952</td>\n",
       "      <td>243.561232</td>\n",
       "      <td>93.925578</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>7</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>{'classifier': KNeighborsClassifier(n_neighbor...</td>\n",
       "      <td>0.97150</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.963287      0.244737       311.222089       22.211935   \n",
       "1       5.523836      2.353290       324.330310        4.107602   \n",
       "2       4.222510      2.090952       243.561232       93.925578   \n",
       "\n",
       "                      param_classifier param_classifier__n_neighbors  \\\n",
       "0  KNeighborsClassifier(n_neighbors=3)                             3   \n",
       "1  KNeighborsClassifier(n_neighbors=3)                             5   \n",
       "2  KNeighborsClassifier(n_neighbors=3)                             7   \n",
       "\n",
       "   param_scaler                                             params  \\\n",
       "0  Normalizer()  {'classifier': KNeighborsClassifier(n_neighbor...   \n",
       "1  Normalizer()  {'classifier': KNeighborsClassifier(n_neighbor...   \n",
       "2  Normalizer()  {'classifier': KNeighborsClassifier(n_neighbor...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.97415             0.9752             0.9727         0.974017   \n",
       "1            0.97330             0.9744             0.9719         0.973200   \n",
       "2            0.97150             0.9723             0.9712         0.971667   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.001025                1  \n",
       "1        0.001023                2  \n",
       "2        0.000464                3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame(data=grid.cv_results_)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "253b04ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: Pipeline(steps=[('scaler', Normalizer()),\n",
      "                ('classifier', KNeighborsClassifier(n_neighbors=3))])\n",
      "best params: {'classifier': KNeighborsClassifier(n_neighbors=3), 'classifier__n_neighbors': 3, 'scaler': Normalizer()}\n",
      "best accuracy:  0.974%\n"
     ]
    }
   ],
   "source": [
    "# after a long time of calculations the best hyperparameters are as follows:\n",
    "print(f\"best estimator: {grid.best_estimator_}\")\n",
    "print(f\"best params: {grid.best_params_}\")\n",
    "print(f\"best accuracy: {grid.best_score_: .3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d649f4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', Normalizer()),\n",
       "                ('classifier', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the final model on the entire data set\n",
    "model = Pipeline([\n",
    "    (\"scaler\", Normalizer()),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=3)),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a53d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.977%\n"
     ]
    }
   ],
   "source": [
    "# applying the model to the test set and see the accuracy of final model\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"accuracy: {accuracy_score(y_test, y_pred)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b61d3",
   "metadata": {},
   "source": [
    "### Not bad! But let's try to improve the model with more advanced techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea7f46",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df87dc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When we look at the digits in the dataset, we see that most of the plot is actually white pixels\n",
    "#let's visualize it better with random forest algorithm\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23cbf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9674"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick look at accuracy\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d27f4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = \"hot\",\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ea234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAADxCAYAAACUNE9cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATvElEQVR4nO3dfbBdVX3G8echAiGAZADfsIQoUpHRqoBaBOXFjGKHMsDQIuMraDu+tAgMbe1QARmnU9pSrLWSiQ4FhCIFeZMZRdSAEwQ0QSABLQomBRVLwEiIDWiy+sfdt1xS7vqd3HPi/a19v5+ZzD25v7P23ufm3Cdr77XO2i6lCAAwvK2m+wAAoC8IVAAYEQIVAEaEQAWAESFQAWBECFQAGBECFYAkyfZNtt+2yfdOtv3ZEe/nbNsLRrnNAfZ5su05Q7Q/xPYbo+cRqADGXSbpHZt87x3d90O2Zw3yvFLKGaWUr2/msU1Zd1wnS5pyoEo6RBKBCmBgV0o6wva2kmR7vqTdJC2x/Vbbt9q+w/YVtnfonrPS9hm2l0j6mO07xjdmey/byzbdie0LbR87of3fdtteantf2zfYvt/2B7vnHGL7W7avtn2v7YW2t+pqx9tebnuF7XMm7OOJrid8u6TTu9ex2Pbirn5+t797bH9iQruVtj/Rvc7ltvfufg4flHSK7Tttv2myH+Bzaj/d7W0+RgVsYetK8TDtDz/88LJ69eqBnrts2bJ7JK2f8K1FpZRFklRKedT2dyQdLulajfVOL5e0i6S/kbSglLLO9l9JOlXS2d021pdSDpIk2wtsv6aUcqekEyRdOMBhPVhKOcD2ed3zD5Q0W9I9khZ2z3m9pH0krZL0VUnH2P62pHMk7SfpF5K+ZvuoUso1kraXtKKUckZ3XCdKOrSUMv6DOr2U8ljXe/2G7d8rpdzd1VaXUva1/WFJp5VSPmB7oaQnSin/WHsh1UAFkN/q1Y9o6dLbB3quvfX6Usr+laeMn/aPB+qJkn5fY2F2i21J2kbSrRPaXD7h8eclnWD7VEnHaSwII9d1X5dL2qGUslbSWtvrbc/tat8ppTww9hp8maSDJP1a0k2llEe6718q6c2SrpG0QdKXKvv8Y9t/qrEMfFH3+sYD9aru6zJJxwxw/P+HQAV64Tej2tA1kv7J9r6Stiul3GH7xZJuLKUcP0mbdRMef0nSmZK+KWlZKeXRAfb5ZPd144TH438fz6hNz5aLpFrPfn0pZcOzFWy/RNJpkl5XSvmF7Qs11iPe9Hg2aDMzkmuoQPOKxgJ1kD/Blkp5QtJNki7Q04NRt0k60PbLJMn2HNu/O0n79ZJukHS+pH+b6it6Fq+3/ZLu2ulxkpZIul3SwbZ37U7dj5d08yTt10rasXv8XI39J/BL2y+Q9PYB9j+x/aQIVKB5owvUzmWSXi3pi5LUnVK/T9Jltu/WWMDuXWl/aXdQX9u811F1q6S/k7RC0o8lXV1K+Zmkv5a0WNJdku4opVw7SftFkr5ie3Ep5S5J39PYNdoLJN0ywP6/LOnoaFDKteX7GJQCtrxhB6X23//VZenSGwZ6rv2iZcE11KHZPk3STqWUj49oe4dobHDoiFFsb0viGirQvPEe6vSzfbWkPSUdNt3HMh0IVKAXcgRqKeXoLbDNmzR2XTc9AhVoXtHYgDSmG4EKNC/PKf9MR6ACzSNQsyBQgeYVPfPTpJguBCrQPHqoWRCoQPMI1CwIVKB5BGoWBCrQCwRqBgTqFjA7qNeWNY9mE0bbjqyLnzKpgZZjHwLDKlO1Ufz0ciBQgeZxyp8FgQo0j0DNgkAFeoFAzYBABZpHDzULAhVoHoGaBYEKNG/TWzFhuhCozyKaHrR1UJ8T1Hep1KJpUYcG9Y1Bfaeg/qpKLZqYM9nNfMatCuoPVGqPBG2jY+v/4nb0UDMgUIHmccqfBYEKNI9AzYJABZpHoGZBoALNI1CzIFCB5rHAdBYEKtA8eqhZEKhA8wjULGZkoEbzSLcJ6jsH9T2C+l6VWm2OqhTPQ703qO8d1G+r1H4+5L7XBvWnKrVtg7bRPNOtgno0fzf3PFYCNYsZGahA/xCoGRCoQPNYYDoLAhVoHqf8WRCoQC/kvso7UxCoQPPooWZBoALNI1CzIFCB5hGoWTQbqNGapbV5h9sHbaN5pgcH9dqaopL0rkpt+4OCxsF9oA+5IGj/snr5sCMnr922uN726GDXXw/qd1Rq0dzhXwb1B4P6mqCe+wolo/xZNBuoACaih5oBgQo0j1P+LAhUoHkEahYEKtA8AjULAhVoHoGaBYEKNI8FprMgUIHm0UPNIm2gRvNMo3mJcyq1FwZtXx7UozVFXxnUa3MiZy+pt52/W7DxG4P6vwf1ByYvRfN3Zwf1aC7ngkotWks1Wqs1er9UXrYk6dFK7ddB2y2PQM0ibaACGBSBmgWBCvRC7s9yzRQEKtA8PnqaBYEKNI9T/iwIVKAXCNQMCFSgefRQs2g2UKNpMDXR5ftoytaaoP5YUK9N0XlD0Dbc+YeiDQQq6+Btu6jedG6w6WOD+nVBvSa6zfTuQT2a+lSbNjX9CNQsmg1UAOMI1CwIVKAPNjBtKgMCFWhdEdNQkyBQgdYRqGkQqEAfbJzuA4BEoALto4eaBoEK9AE91BTSBmrtNtBS/P6pLSUXzTP9VVCvLQ0oxZ2Fd7918tpTXwsavy2onxzU3xPUKxM2o1s17xnUn79Dvb7qiclrPwy2/ZOgHr2fIrX307Qv31ckPTXdBwEpcaACGFARPdQkCFSgD7iGmgKBCrSOQak0CFSgDzjlT4FABVpXlGBkDBKBCrSPU/40CFSgdQRqGtMWqNFc0Ei0/mXtVtHRvp8X1N8b1NcFdb1r8tI29wZtrw/qewT1lwb1cyYvve7IoO1eQf3KevmllXmoNwebjuYO127dLcXLzKY/o+Yaagr0UIHW0UNNg0AF+oBATYFABVrHKH8aBCrQOj56mgaBCvQBp/wpEKhA6xiUSoNABfqAU/4Umg3U6Br8mkptt6DtzkE9mmc67yPBE346xZqk+4NfnN1+VK9vd1e9rn0rtagXFCxaumFVvV6bHxxNr43+TaL62qCeugNIDzWNZgMVQIdR/jQIVKAP6KGmQKACrWPaVBoEKtAH9FBTIFCB1jEolQaBCrSOQak0CFSgdfRQ05i2QI3+/bcO6tGaprV65dbzkuprqUrSvPcHT4gWVH17pXZZvencYB7pducG+67dYF6SLqnUvhK0razzKkmztqrXV1YGVt4U7PrFQf2BoP5QUE8/5pP+AGcGeqhA6+ihpkGgAn1ADzUFAhVoHT3UNAhUoHWM8qdBoAJ9QA81BQIVaB0fPU0jbaBG/+EGM3D0gkotmmLz2qCuU4L6nwf1M984ee2Ab1eb7hLdD/nUa+r1dx1VLW+4dfLarAOCfa+sl78a/NL/Z6UWzfZ6OKhHZ8TR+y19BzD9Ac4MaQMVwIAYlEqDQAVax6BUGgQq0Dp6qGkQqEAfMCiVAoEKtI4eahoEKtAH9FBTIFCB1tFDTaPZQI3mJdbq0XvvwAXBE84P6qcH9dqEzV2Cpo/uEzxhz3r52Hp5Vu1+yh+ot11+ZL2+ol6u3oX6xqBtcGjaK6jfG9RTY5Q/jWYDFcAE9FBTIFCB1nHKnwaBCvQBg1IpEKhA6+ihpkGgAn1ADzUFAhVoXZH01HQfBCQCFWgf66Gm0WygbjNEPbpNtD4e1BcF9drCnpJ07k8nr/0gaPvJU4MnBAd3VtD8nZXaH5agsavVNUHr2tzh44K2S4L6nUF9TlCvTfNMcfkyxUGg2UAF0GFQKg0CFegDTvlTIFCB1m0UHz1NgkAF+oBT/hQIVKB1XENNg0AF+oBrqCkQqEDr6KGmkTZQo/9wdxyi/tpo5x8L6r8K6sGao9UJl/8ctNVv6uXb/qVe3zrY/EtrxZ2qTdcEmw7n/1bcNWR9VlB/cjOOJSUCNYW0gQpgQCwwnQaBCrSOj56mQaACfcApfwoEKtA6BqXSIFCBPuCUPwUCFWgdPdQ0CFSgdYzyp5E2UKPpkrXbx0vSgkrtedHOowmTtXmkkvT5oP7zSu3RoK0Orpcvq5e/u7Re36Myh/b5Rz9ebRv9Tu8W1GtbfyxoGy1YH71fmkYPNY20gQpgM3ANNQUCFWgdPdQ0CFSgDwjUFAhUoHUMSqVBoAKt45Q/DQIV6AMGpVKYtkCNllOL6i8I6vdWajsHbWdfXa/POynYwB5B/bBKLXrhP35FvX50vbzm0/X6VpXa86+vt72/Xg5no1Vurq31QdsZfcZLDzUNeqhAH9BDTYFABVpHDzUNAhVoHaP8aRCoQB/QQ02BQAVaxyl/GgQq0AcMSqVAoAI9QAc1h2YDNbqT84OVWjSncV4wj7QEczldm1ApSV+v1ILl9XRDvXzFpfV6tAze5ZXa24KBj9qqhJJ0YlC/fYhtRysqrgnq0XKR0XtmOnHGn0ezgQpgDIP8eRCoQA9wCTUHAhVoHKf8eRCoQOMI1DwIVKAHOOXPgUAFGlcU36QQvx0EKtC4InqoWUxboNbW3RxFfX6ldlTUOJjU6POD9nODem2OyzfrTf9rRb0ezTN9JKjXfjH3Dtr+0e/U6w8/VK+/ulJ7INj33KC+LqhH046yX6PMfnwzBT1UoHH0UPMgUIEeoIeaA4EKNI5pU3kQqEDj+OhpHgQq0Dh6qHkQqEAPMCiVA4EKNI4eah5pAzVa33KboP68WvFVQePTg/qaoH5JUD958tJ/Bwu93hxsOvrF2nGI+lVB29uCeabRHNm1U6wNUh9m3y2gh5pD2kAFMBg+epoHgQo0jon9eRCoQA9wDTUHAhVoHINSeRCoQA9wyp8DgQo0jh5qHtMWqNH/qNFtoqNl6GrTixbcVW+7d+02z5IeX1SvR8d2baU27PSfuUH94aA+p1JbFbSN7p4dLaFXax+9X+4P6tH7qeWPbvLR0zzooQI9QA81BwIVaBzTpvIgUIEeoIeaA4EKNI5BqTwIVKAHOOXPgUAFGrdRjPJnQaACPcApfw7TFqjRGyCqR3Maf1KpXR9tO5hnut+u9fpzd6/Xd/ze5LWop/GGoL4yqEcrF9bmqf48aBvdnTu6FXRtjm30c3kyqLd+m+garqHmQQ8V6AGuoeZAoAKNo4eaB4EKNI6PnuZBoAI9QA81BwIVaBwfPc2DQAV6gB5qDgQq0DgGpfJIG6jRRfZo3dBfVmo3BG2j+ZKPrK7XDw/ugf0nr6gUFwY7PymoB7e/vOX79frtlVr0Mw+WmR3qVs7R+2F9UO974HDKn0PaQAUwmI3iNtJZEKhAD9BDzYFABRrHNdQ8CFSgB+ih5kCgAo2jh5oHgQr0AIGaA4EKNI7P8ueRNlCj/3GjtTcfr9SiKSZrgvrKoH7lQ/X6iyu1pw6ut43uL78yqEdq24/WoH0kqEfX+aK5pDUzuYfGKX8eaQMVwOAYlMqBQAUaRw81DwIV6AF6qDkQqEDjivjoaRYEKtA41kPNg0AFeoBrqDkQqEDjGJTKo9lAjU5xavMpo7bBcqbhJOo7gnptvuYLg7YPB/UfBfVorufWQX2YbQ9zWsrE9clxyp9Hs4EK4Gn0UHMgUIHG8dHTPAhUoHFcQ82DQAV6gGuoORCoQOPooeZBoAI9QKDm0GygRm+gWn3YW1SvCurR0oK121RHU7ZmDbnvaPm/2v6jaVHDDowQClPDtKk8mg1UAGMY5c+DQAV6gN59DgQq0DgGpfIgUIEe4BpqDgQq0Dh6qHkQqEDjGJTKg0AFGkcPNY8ZGahb+s03zPanu6cxzK2cMX24hprDjAxUoE/ooeZBoAI9QKDmQKACjeOjp3kQqEDjuI10HtFaGgAasHHAPxHbxfa5E/5+mu2zgjZH2d5nktoHbb9noBcxIrbfZ3u3Idq/xvYfTKUtgQo0bnxQapA/A3hS0jG2d92MQzhK0rMGaillYSnl4s3Y1lBsz5L0PklTDlRJr5FEoAIz1ah6qJJ+I2mRpFM2Ldjew/Y3bN/dfZ1n+42SjpT0D7bvtL3nJm3Osn1a9/gm2+fZ/pbt79t+ne2rbP/Q9ie758y3/QPbF3X7udL2nK72Ftvfs73c9gW2t+2+v9L2GbaXSDpe0v6SLu2OZ7uu9l3bK2wvsu0Jx3OO7e/Yvs/2m2xvI+lsScd17Y8b/F8huIa6rhRvzsYA/PZtlG5YJw3ao5xte+mEvy8qpSza5Dn/Kulu23+/yfc/I+niUspFtk+U9OlSylG2r5N0fSnlygH2/1Qp5c22PyrpWkn7SXpM0v22z+ue83JJ7y+l3GL7Akkftv0ZSRdKeksp5T7bF0v6kKRPdW3Wl1IOkiTbH5B0Willaff3z5RSzu4ef0HSEZK+3LV7Tinl9d0p/pmllAW2z5C0fynlzwZ4Pc/AoBTQuFLK4SPe3uNdYJ0k6X8mlA6QdEz3+AuSNg3cQVzXfV0u6Z5Sys8kyfYDknaXtEbSg6WUW7rnXdIdx42SflxKua/7/kWSPqKnA/Xyyj4Ptf2XkuZI2lnSPXo6UK/qvi6TNH8Kr+cZOOUH8Gw+Jen9kravPKdMYbtPdl83Tng8/vfxDt6m2y2SorPldc/2TduzJX1W0rGllFdJ+pyeeWOK8WPYoBF0MAlUAP9PKeUxSf+hsVAd921J7+gev1PSku7xWkk7jnD382wf0D0+vtvPDyTNt/2y7vvvlnTzJO0nHs94eK62vYOkYwfY/5RfD4EKYDLn6pnXZk+SdILtuzUWaB/tvv9FSX/RDRjtqeF9X9J7u/3sLOn8Usp6SSdIusL2co31aBdO0v5CSQtt36mxHujnNHaJ4RpJ3x1g/4sl7TOVQSmXMpVeOwCMnu35GhvgeuV0H8tU0EMFgBGhhwoAI0IPFQBGhEAFgBEhUAFgRAhUABgRAhUARuR/ARm52QB80KLdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "heatmap = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
    "heatmap.ax.set_yticklabels(['Not important', 'Very important'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b03fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the sides of the photo have practically no effect on the accuracy of the algorithm\n",
    "#Maybe PCA will reduce number of features and boost learning of the model? Let's try\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0164c84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c11946cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looks like PCA reduced number of dimension to only 154! That's muuuch less than 784\n",
    "#but what with accuracy?\n",
    "rnd_clf.fit(X_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7da1f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fast look on the accuracy\n",
    "y_pred = rnd_clf.predict(pca.transform(X_test))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#well...I expected much better result, but I don't give up :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe4496",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e904b12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kmeans', KMeans(n_clusters=200)),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sometimes clustering is good in preprocessing data, let's see\n",
    "from sklearn.cluster import KMeans\n",
    "pipe = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters = 200)),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25426f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a4dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again there is no improvment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d8492",
   "metadata": {},
   "source": [
    "# Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1c98201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the most powerful (and my favourites) algorithms is XGBoost, let's see how it will perform\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "params = [\n",
    " dict(\n",
    "    max_depth=[2,4,6],           # maximum depth of each tree - try 2 to 10\n",
    "#     learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n",
    "#     n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "#     min_child_weight=1,    # minimum number of houses in a leaf - try 1 to 10\n",
    "#     colsample_bytree=0.7,  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "#     subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "#     reg_alpha=0.5,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "#     reg_lambda=1.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "#     num_parallel_tree=1,   # set > 1 for boosted random forests    \n",
    " )]\n",
    "grid = GridSearchCV(xgb_clf, params, cv=3, scoring = \"accuracy\", n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4375918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_pliki_instalacyjne\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=5, param_grid=[{'max_depth': [2, 4, 6]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b7c1f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>571.679082</td>\n",
       "      <td>1.519690</td>\n",
       "      <td>0.586990</td>\n",
       "      <td>0.059388</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.93765</td>\n",
       "      <td>0.93755</td>\n",
       "      <td>0.93825</td>\n",
       "      <td>0.937817</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080.781249</td>\n",
       "      <td>119.825314</td>\n",
       "      <td>0.467795</td>\n",
       "      <td>0.063577</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.97065</td>\n",
       "      <td>0.97030</td>\n",
       "      <td>0.96995</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1253.261217</td>\n",
       "      <td>216.596030</td>\n",
       "      <td>0.387331</td>\n",
       "      <td>0.089442</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.97360</td>\n",
       "      <td>0.97475</td>\n",
       "      <td>0.97345</td>\n",
       "      <td>0.973933</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     571.679082      1.519690         0.586990        0.059388   \n",
       "1    1080.781249    119.825314         0.467795        0.063577   \n",
       "2    1253.261217    216.596030         0.387331        0.089442   \n",
       "\n",
       "  param_max_depth            params  split0_test_score  split1_test_score  \\\n",
       "0               2  {'max_depth': 2}            0.93765            0.93755   \n",
       "1               4  {'max_depth': 4}            0.97065            0.97030   \n",
       "2               6  {'max_depth': 6}            0.97360            0.97475   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.93825         0.937817        0.000309                3  \n",
       "1            0.96995         0.970300        0.000286                2  \n",
       "2            0.97345         0.973933        0.000581                1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame(data=grid.cv_results_)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54242d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "with open(\"model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
